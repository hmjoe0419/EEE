{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb92212c-21b2-47b4-b469-868a16cd2b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully!\n",
      "Class distribution in dataset:\n",
      "Label\n",
      "NORMAL                 1398\n",
      "REPLAY                  466\n",
      "COLD_RESTART            466\n",
      "DNP3_INFO               466\n",
      "DNP3_ENUMERATE          466\n",
      "WARM_RESTART            466\n",
      "DISABLE_UNSOLICITED     466\n",
      "INIT_DATA               466\n",
      "STOP_APP                466\n",
      "Name: count, dtype: int64\n",
      "Training Random Forest Classifier...\n",
      "Random Forest Classifier trained!\n",
      "\n",
      "Classification Report for Testing Dataset:\n",
      "Accuracy: 0.9932\n",
      "Precision: 0.9922\n",
      "Recall: 0.9987\n",
      "F1 Score: 0.9954\n",
      "ROC-AUC: 0.9997\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256   6]\n",
      " [  1 763]]\n",
      "\n",
      "Evaluating for 1% intrusion rate:\n",
      "Class distribution after filtering:\n",
      "Label\n",
      "NORMAL            1398\n",
      "COLD_RESTART         4\n",
      "STOP_APP             2\n",
      "DNP3_INFO            2\n",
      "WARM_RESTART         2\n",
      "INIT_DATA            1\n",
      "DNP3_ENUMERATE       1\n",
      "REPLAY               1\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.9859\n",
      "Precision: 0.2000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.3333\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Evaluating for 3% intrusion rate:\n",
      "Class distribution after filtering:\n",
      "Label\n",
      "NORMAL            1398\n",
      "REPLAY               8\n",
      "DNP3_INFO            7\n",
      "STOP_APP             7\n",
      "COLD_RESTART         6\n",
      "DNP3_ENUMERATE       5\n",
      "INIT_DATA            5\n",
      "WARM_RESTART         3\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.9965\n",
      "Precision: 0.9091\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9524\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Evaluating for 5% intrusion rate:\n",
      "Class distribution after filtering:\n",
      "Label\n",
      "NORMAL                 1398\n",
      "DNP3_INFO                15\n",
      "REPLAY                   11\n",
      "STOP_APP                 10\n",
      "INIT_DATA                 9\n",
      "COLD_RESTART              8\n",
      "DNP3_ENUMERATE            7\n",
      "WARM_RESTART              6\n",
      "DISABLE_UNSOLICITED       3\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.9898\n",
      "Precision: 0.8636\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9268\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Evaluating for 7% intrusion rate:\n",
      "Class distribution after filtering:\n",
      "Label\n",
      "NORMAL                 1398\n",
      "STOP_APP                 19\n",
      "DNP3_INFO                17\n",
      "REPLAY                   14\n",
      "DNP3_ENUMERATE           12\n",
      "COLD_RESTART             11\n",
      "INIT_DATA                10\n",
      "WARM_RESTART              8\n",
      "DISABLE_UNSOLICITED       6\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.9866\n",
      "Precision: 0.8261\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9048\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Summary of Results:\n",
      "\n",
      "Intrusion Rate: 1%\n",
      "Accuracy: 0.9859\n",
      "Precision: 0.2000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.3333\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Intrusion Rate: 3%\n",
      "Accuracy: 0.9965\n",
      "Precision: 0.9091\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9524\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Intrusion Rate: 5%\n",
      "Accuracy: 0.9898\n",
      "Precision: 0.8636\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9268\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Intrusion Rate: 7%\n",
      "Accuracy: 0.9866\n",
      "Precision: 0.8261\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9048\n",
      "ROC-AUC: 1.0000\n",
      "\n",
      "Feature Importances:\n",
      "[0.04930287 0.1306447  0.02992964 0.12699105 0.02196333 0.0484404\n",
      " 0.02934371 0.02111199 0.01964623 0.09878346 0.01134168 0.02490866\n",
      " 0.03275662 0.14556082 0.01197682 0.04082446 0.02441587 0.02374071\n",
      " 0.03254002 0.07577697]\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Changed to Random Forest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\haris\\OneDrive\\Desktop\\Augmented_DNP3_Parser_Training.csv\"  # Change this path as needed\n",
    "print(\"Loading dataset...\")\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Dataset loaded successfully!\")\n",
    "\n",
    "# Standardize column names by stripping whitespace\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Debug: Check class distribution in the dataset\n",
    "print(\"Class distribution in dataset:\")\n",
    "print(data['Label'].value_counts())\n",
    "\n",
    "# Split data into features and labels\n",
    "features = data.select_dtypes(include=['float64', 'int64']).drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'Label'], errors='ignore')\n",
    "labels = data['Label'].apply(lambda x: 0 if x == 'NORMAL' else 1)  # 0: Normal, 1: Anomalous\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA for dimensionality reduction (Fit PCA only on training data)\n",
    "pca = PCA(n_components=20, random_state=42)  # Increase PCA components to retain more variance\n",
    "X_train_reduced = pca.fit_transform(X_train_scaled)\n",
    "X_test_reduced = pca.transform(X_test_scaled)\n",
    "\n",
    "# Train Random Forest Classifier with optimized parameters\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,         # Reduced the number of trees to avoid overfitting\n",
    "    max_depth=5,              # Limited tree depth to prevent overfitting\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # Adjusted to handle class imbalance\n",
    ")\n",
    "rf_model.fit(X_train_reduced, y_train)\n",
    "print(\"Random Forest Classifier trained!\")\n",
    "\n",
    "# Evaluate on the testing dataset\n",
    "print(\"\\nClassification Report for Testing Dataset:\")\n",
    "y_pred = rf_model.predict(X_test_reduced)\n",
    "y_proba_pred = rf_model.predict_proba(X_test_reduced)[:, 1]\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_pred)\n",
    "\n",
    "# Print metrics with 4 decimal places\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Function to filter dataset based on intrusion rate\n",
    "def filter_intrusion_rate(data, rate):\n",
    "    \"\"\"\n",
    "    Filters the dataset to have a specified percentage of intrusion data.\n",
    "    Args:\n",
    "        data (pd.DataFrame): Dataset containing both normal and anomalous data.\n",
    "        rate (float): Desired percentage of anomalous data (0-100).\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered dataset with the specified intrusion rate.\n",
    "    \"\"\"\n",
    "    normal_data = data[data['Label'] == 'NORMAL']\n",
    "    anomalous_data = data[data['Label'] != 'NORMAL']\n",
    "    \n",
    "    # Sample the number of anomalous instances based on the desired rate\n",
    "    num_anomalous = int(len(normal_data) * rate / 100)\n",
    "    num_anomalous = min(num_anomalous, len(anomalous_data))  # Avoid sampling more than available\n",
    "    \n",
    "    sampled_anomalous_data = anomalous_data.sample(n=num_anomalous, random_state=42)\n",
    "    \n",
    "    # Return the filtered dataset\n",
    "    return pd.concat([normal_data, sampled_anomalous_data]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Intrusion rates to evaluate\n",
    "intrusion_rates = [1, 3, 5, 7]\n",
    "\n",
    "# Store results for each intrusion rate\n",
    "results = {}\n",
    "\n",
    "for rate in intrusion_rates:\n",
    "    print(f\"\\nEvaluating for {rate}% intrusion rate:\")\n",
    "    \n",
    "    # Filter dataset for both training and testing data\n",
    "    filtered_data = filter_intrusion_rate(data, rate)\n",
    "    \n",
    "    # Debug: Check class distribution after filtering\n",
    "    print(\"Class distribution after filtering:\")\n",
    "    print(filtered_data['Label'].value_counts())\n",
    "    \n",
    "    # Split filtered data into features and labels (Training data)\n",
    "    X_train_filtered = filtered_data.select_dtypes(include=['float64', 'int64']).drop(columns=['Unnamed: 0.1', 'Unnamed: 0', 'Label'], errors='ignore')\n",
    "    y_train_filtered = filtered_data['Label'].apply(lambda x: 0 if x == 'NORMAL' else 1).values\n",
    "    \n",
    "    # Split filtered data into features and labels (Testing data)\n",
    "    X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(\n",
    "        X_train_filtered, y_train_filtered, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Standardize features using the same scaler\n",
    "    X_train_scaled_filtered = scaler.transform(X_train_filtered)\n",
    "    X_test_scaled_filtered = scaler.transform(X_test_filtered)\n",
    "    \n",
    "    # Apply PCA for dimensionality reduction on filtered data\n",
    "    X_train_reduced_filtered = pca.transform(X_train_scaled_filtered)\n",
    "    X_test_reduced_filtered = pca.transform(X_test_scaled_filtered)\n",
    "    \n",
    "    # Predict using trained model on filtered test data\n",
    "    y_pred_filtered = rf_model.predict(X_test_reduced_filtered)\n",
    "    y_proba_pred_filtered = rf_model.predict_proba(X_test_reduced_filtered)[:, 1]\n",
    "    \n",
    "    # Calculate performance metrics for filtered data\n",
    "    accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "    precision_filtered = precision_score(y_test_filtered, y_pred_filtered)\n",
    "    recall_filtered = recall_score(y_test_filtered, y_pred_filtered)\n",
    "    f1_filtered = f1_score(y_test_filtered, y_pred_filtered)\n",
    "    roc_auc_filtered = roc_auc_score(y_test_filtered, y_proba_pred_filtered)\n",
    "    \n",
    "    results[rate] = {\n",
    "        'Accuracy': accuracy_filtered,\n",
    "        'Precision': precision_filtered,\n",
    "        'Recall': recall_filtered,\n",
    "        'F1 Score': f1_filtered,\n",
    "        'ROC-AUC': roc_auc_filtered\n",
    "    }\n",
    "    \n",
    "    # Print metrics for filtered data with 4 decimal places\n",
    "    print(f\"Accuracy: {accuracy_filtered:.4f}\")\n",
    "    print(f\"Precision: {precision_filtered:.4f}\")\n",
    "    print(f\"Recall: {recall_filtered:.4f}\")\n",
    "    print(f\"F1 Score: {f1_filtered:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_filtered:.4f}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for rate, metrics in results.items():\n",
    "    print(f\"\\nIntrusion Rate: {rate}%\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "    print(f\"ROC-AUC: {metrics['ROC-AUC']:.4f}\")\n",
    "\n",
    "# Feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(importances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e9e85-6608-4e7c-87d4-2eeeab5f9ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
